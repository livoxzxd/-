# 该仓库采用多项式朴素贝叶斯分类器

## 一、条件概率与特征独立性假设

多项式朴素贝叶斯分类器基于以下两个核心假设

**条件独立性假设**

   假设所有特征（在文本分类中通常是词或标记）在给定类别条件下相互独立。这意味着一个词的出现概率与其他词的出现概率无关。

   数学表达为：P(x₁, x₂, ..., xₙ|y) = P(x₁|y) × P(x₂|y) × ... × P(xₙ|y)
   
**多项式分布假设**
   假设特征服从多项式分布，即每个特征（词）的出现次数被建模。

## 贝叶斯定理在邮件分类中的应用

### 在邮件分类（如垃圾邮件/正常邮件分类）中，贝叶斯定理的具体应用形式如下：

**基本贝叶斯公式**
   
   P(y|x₁, x₂, ..., xₙ) = [P(y) × P(x₁, x₂, ..., xₙ|y)] / P(x₁, x₂, ..., xₙ)

**应用于邮件分类**
   
   对于一封包含词{w₁, w₂, ..., wₙ}的邮件，我们计算：
   
   P(Spam|w₁, w₂, ..., wₙ) ∝ P(Spam) × Π P(wᵢ|Spam)
   
   P(Ham|w₁, w₂, ..., wₙ) ∝ P(Ham) × Π P(wᵢ|Ham)

**具体计算步骤**
- 计算先验概率P(Spam)和P(Ham)
- 计算每个词在垃圾邮件和正常邮件中的条件概率P(wᵢ|Spam)和P(wᵢ|Ham)
- 对于新邮件，将所有词的条件概率相乘，再乘以先验概率
- 比较两个结果，选择概率较大的类别作为预测结果

**平滑处理**
   为避免零概率问题（未在训练集中出现的词），通常使用拉普拉斯平滑
   
   P(wᵢ|y) = (count(wᵢ, y) + α) / (∑count(w, y) + α|V|)
   
   其中α是平滑参数，|V|是词汇表大小

## 多项式朴素贝叶斯的优势

- 计算高效，特别适合高维文本数据
- 对小规模数据集也能表现良好
- 对无关特征相对鲁棒（由于独立性假设）
- 易于实现和理解

尽管独立性假设在现实中通常不成立（词之间往往有关联），但多项式朴素贝叶斯在文本分类任务中仍然表现出色，这被称为"朴素贝叶斯悖论"

## 二、特征选择方法对比分析

### 高频词特征选择(Top-k Frequent Terms)

**数学表达**
- 词项t在文档集D中的频率：`freq(t) = Σ count(t,d), ∀d∈D`
- 选择频率最高的k个词作为特征：`Features = argmaxₜ(freq(t), k)`

**特点**
- 简单直观，计算复杂度O(n)
- 倾向于选择常见但区分度不高的词
- 可能保留无意义的频繁词(如"the","and")

### 2. TF-IDF特征加权

**数学表达**
- 词频(TF): `tf(t,d) = count(t,d) / len(d)`
- 逆文档频率(IDF): `idf(t,D) = log(|D| / |{d∈D:t∈d}|)`
- TF-IDF: `tfidf(t,d,D) = tf(t,d) * idf(t,D)`

**特点**
- 惩罚常见词，提升稀有词权重
- 计算复杂度O(n + nlogm)(n为词数，m为文档数)
- 更有效捕捉有区分度的特征


### 高频词特征运行结果截图
![高频词特征运行结果](./高频词特征运行结果.png)

### TF-IDF运行结果截图
![TF-IDF运行结果](./TF-IDF运行结果.png)
